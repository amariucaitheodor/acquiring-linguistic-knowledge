program: train.py
name: bert-text-wit
description: Hyperparameter sweep search for BERT (text) on the WiT dataset.
project: alkmi-wit
run_cap: 100
entity: rycolab
method: bayes # uses probability of improvement (PI) to select the next hyperparameter configuration
metric:
  name: evaluation/pseudo_perplexity
  goal: minimize
command:
  - ${env}
  - ${interpreter} # makes sure the right interpreter is used on Euler (3.10 req. for BLiMP)
  - -m
  - train
  - config=configs/bert/wit.yaml
parameters:
  mlm_perc:
    distribution: categorical
    values: [ 0.15, 0.3, 0.4 ]
  learning_rate:
    distribution: categorical
    values: [ 1e-3, 5e-4, 1e-4, 5e-5 ] # FLAVA, NYU RoBERTa training, BERT, half-BERT
