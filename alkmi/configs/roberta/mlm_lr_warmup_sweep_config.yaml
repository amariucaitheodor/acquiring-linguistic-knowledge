program: train.py
name: roberta-text-wit
description: Hyperparameter sweep search for RoBERTa (text) on the WiT dataset.
project: multimodal-wit
run_cap: 100
entity: rycolab
method: bayes # uses probability of improvement (PI) to select the next hyperparameter configuration
metric:
  name: evaluation/blimp/average
  goal: maximize
command:
  - ${env}
  - ${interpreter} # makes sure the right interpreter is used on Euler (3.10 req. for BLiMP)
  - -m
  - train
  - config=configs/roberta/wit.yaml
early_terminate: # We do want to early_terminate here because we're interested in the best configs.
  type: hyperband
  max_iter: 32
  s: 4
  eta: 2
parameters:
  mlm_perc:
    distribution: uniform
    min: 0.15
    max: 0.5
  learning_rate:
    distribution: categorical
    values: [ 1e-3, 4e-4, 6e-4, 5e-4, 1e-4 ] # FLAVA, RoBERTa LARGE, RoBERTa BASE, NYU RoBERTa training, BERT
