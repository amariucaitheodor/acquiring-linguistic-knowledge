program: train.py
name: roberta-text-wit
description: Hyperparameter sweep search for RoBERTa (text) on the WiT dataset.
project: alkmi-wit
run_cap: 100
entity: rycolab
method: bayes # uses probability of improvement (PI) to select the next hyperparameter configuration
metric:
  name: evaluation/pseudo_perplexity
  goal: minimize
command:
  - ${env}
  - ${interpreter} # makes sure the right interpreter is used on Euler (3.10 req. for BLiMP)
  - -m
  - train
  - config=configs/roberta/wit.yaml
parameters:
  mlm_perc:
    distribution: categorical
    values: [ 0.15, 0.3, 0.4 ]
  learning_rate:
    distribution: categorical
    values: [ 3e-3, 2e-3, 1e-3, 6e-4, 5e-4 ] # FLAVA x3x2x1, RoBERTa BASE, NYU RoBERTa training
