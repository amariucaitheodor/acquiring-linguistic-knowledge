@misc{AlexThesis,
	title        = {
		What Artificial Neural Networks Can Tell Us About Human Language Acquisition
	},
	author       = {Warstadt, Alex and Bowman, Samuel R.},
	year         = 2022,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2208.07998},
	url          = {https://arxiv.org/abs/2208.07998},
	copyright    = {
		Creative Commons Attribution Non Commercial No Derivatives 4.0 International
	},
	keywords     = {
		Computation and Language (cs.CL), FOS: Computer and information sciences,
		FOS: Computer and information sciences
	}
}
@misc{BERT,
	title        = {
		BERT: Pre-training of Deep Bidirectional Transformers for Language
		Understanding
	},
	author       = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year         = 2018,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1810.04805},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	comment      = {
		Section 3.1: Describes MLM & next sentence prediction task -> NSP task
		dropped in BERT? Appendix C.2: Ablation for Different Masking Procedures  ->
		I think mask 100% is good enough? Others don't seem to make a difference

		Misc: BERT Medium model available at https://github.com/google-research/bert
	},
	file         = {
		:Devlin2018 - BERT_ Pre Training of Deep Bidirectional Transformers for
		Language Understanding.pdf:PDF
	},
	keywords     = {
		Computation and Language (cs.CL), FOS: Computer and information sciences,
		FOS: Computer and information sciences
	},
	priority     = {prio2},
	readstatus   = {skimmed}
}
@misc{BLiMP,
	title        = {BLiMP: The Benchmark of Linguistic Minimal Pairs for English},
	author       = {
		Warstadt, Alex and Parrish, Alicia and Liu, Haokun and Mohananey, Anhad and
		Peng, Wei and Wang, Sheng-Fu and Bowman, Samuel R.
	},
	year         = 2019,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1912.00582},
	url          = {https://arxiv.org/abs/1912.00582},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {
		Computation and Language (cs.CL), FOS: Computer and information sciences,
		FOS: Computer and information sciences
	}
}
@misc{BrownStudy,
	title        = {Does Vision-and-Language Pretraining Improve Lexical Grounding?},
	author       = {Yun, Tian and Sun, Chen and Pavlick, Ellie},
	year         = 2021,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2109.10246},
	url          = {https://arxiv.org/abs/2109.10246},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {
		Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computer
		Vision and Pattern Recognition (cs.CV), FOS: Computer and information
		sciences, FOS: Computer and information sciences
	}
}
@misc{Bugliarello2020,
	title        = {
		Multimodal Pretraining Unmasked: A Meta-Analysis and a Unified Framework of
		Vision-and-Language BERTs
	},
	author       = {
		Bugliarello, Emanuele and Cotterell, Ryan and Okazaki, Naoaki and Elliott,
		Desmond
	},
	year         = 2020,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2011.15124},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	file         = {
		:Bugliarello2020 - Multimodal Pretraining Unmasked_ a Meta Analysis and a
		Unified Framework of Vision and Language BERTs.pdf:PDF
	},
	keywords     = {
		Computation and Language (cs.CL), Computer Vision and Pattern Recognition
		(cs.CV), FOS: Computer and information sciences, FOS: Computer and
		information sciences
	},
	readstatus   = {skimmed}
}
@article{CoLA,
	title        = {Neural Network Acceptability Judgments},
	author       = {Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1805.12471}
}
@misc{data2vec_20,
	title        = {
		Efficient Self-supervised Learning with Contextualized Target Representations
		for Vision, Speech and Language
	},
	author       = {Baevski, Alexei and Babu, Arun and Hsu, Wei-Ning and Auli, Michael},
	year         = 2022,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2212.07525},
	url          = {https://arxiv.org/abs/2212.07525},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {
		Machine Learning (cs.LG), Computation and Language (cs.CL), Sound (cs.SD),
		Audio and Speech Processing (eess.AS), FOS: Computer and information
		sciences, FOS: Computer and information sciences, FOS: Electrical
		engineering, electronic engineering, information engineering, FOS: Electrical
		engineering, electronic engineering, information engineering
	}
}
@misc{DeBERTa,
	title        = {DeBERTa: Decoding-enhanced BERT with Disentangled Attention},
	author       = {He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
	year         = 2020,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2006.03654},
	url          = {https://arxiv.org/abs/2006.03654},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {
		Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and
		information sciences, FOS: Computer and information sciences, I.2; I.7,
		cs.CL, cs.GL
	}
}
@misc{FLAVA,
	title        = {FLAVA: A Foundational Language And Vision Alignment Model},
	author       = {
		Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon,
		Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe
	},
	year         = 2021,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2112.04482},
	copyright    = {Creative Commons Attribution 4.0 International},
	abstract     = {Section 4 very relevant},
	file         = {
		:Singh2021 - FLAVA_ a Foundational Language and Vision Alignment
		Model.pdf:PDF
	},
	keywords     = {
		Computer Vision and Pattern Recognition (cs.CV), Computation and Language
		(cs.CL), FOS: Computer and information sciences, FOS: Computer and
		information sciences
	},
	readstatus   = {read}
}
@misc{MetaASRPaper,
	title        = {Unified Speech-Text Pre-training for Speech Translation and Recognition},
	author       = {
		Tang, Yun and Gong, Hongyu and Dong, Ning and Wang, Changhan and Hsu,
		Wei-Ning and Gu, Jiatao and Baevski, Alexei and Li, Xian and Mohamed,
		Abdelrahman and Auli, Michael and Pino, Juan
	},
	year         = 2022,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2204.05409},
	url          = {https://arxiv.org/abs/2204.05409},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {
		Computation and Language (cs.CL), FOS: Computer and information sciences,
		FOS: Computer and information sciences
	}
}
@misc{RoBERTa,
	title        = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
	author       = {
		Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar
		and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and
		Stoyanov, Veselin
	},
	year         = 2019,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1907.11692},
	url          = {https://arxiv.org/abs/1907.11692},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {
		Computation and Language (cs.CL), FOS: Computer and information sciences,
		FOS: Computer and information sciences
	}
}
@inproceedings{Salazar_2020,
	title        = {Masked Language Model Scoring},
	author       = {Julian Salazar and Davis Liang and Toan Q. Nguyen and Katrin Kirchhoff},
	year         = 2020,
	booktitle    = {
		Proceedings of the 58th Annual Meeting of the Association for Computational
		Linguistics
	},
	publisher    = {Association for Computational Linguistics},
	doi          = {10.18653/v1/2020.acl-main.240},
	url          = {https://doi.org/10.18653%2Fv1%2F2020.acl-main.240}
}
@misc{SLAM,
	title        = {
		SLAM: A Unified Encoder for Speech and Language Modeling via Speech-Text
		Joint Pre-Training
	},
	author       = {
		Bapna, Ankur and Chung, Yu-an and Wu, Nan and Gulati, Anmol and Jia, Ye and
		Clark, Jonathan H. and Johnson, Melvin and Riesa, Jason and Conneau, Alexis
		and Zhang, Yu
	},
	year         = 2021,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2110.10329},
	url          = {https://arxiv.org/abs/2110.10329},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {
		Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and
		information sciences, FOS: Computer and information sciences
	}
}
@misc{SpeechT5,
	title        = {
		SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language
		Processing
	},
	author       = {
		Ao, Junyi and Wang, Rui and Zhou, Long and Wang, Chengyi and Ren, Shuo and
		Wu, Yu and Liu, Shujie and Ko, Tom and Li, Qing and Zhang, Yu and Wei, Zhihua
		and Qian, Yao and Li, Jinyu and Wei, Furu
	},
	year         = 2021,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2110.07205},
	url          = {https://arxiv.org/abs/2110.07205},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {
		Audio and Speech Processing (eess.AS), Computation and Language (cs.CL),
		Machine Learning (cs.LG), Sound (cs.SD), FOS: Electrical engineering,
		electronic engineering, information engineering, FOS: Electrical engineering,
		electronic engineering, information engineering, FOS: Computer and
		information sciences, FOS: Computer and information sciences
	}
}
@misc{SpeechUT,
	title        = {
		SpeechUT: Bridging Speech and Text with Hidden-Unit for Encoder-Decoder Based
		Speech-Text Pre-training
	},
	author       = {
		Zhang, Ziqiang and Zhou, Long and Ao, Junyi and Liu, Shujie and Dai, Lirong
		and Li, Jinyu and Wei, Furu
	},
	year         = 2022,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2210.03730},
	url          = {https://arxiv.org/abs/2210.03730},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {
		Computation and Language (cs.CL), Audio and Speech Processing (eess.AS), FOS:
		Computer and information sciences, FOS: Computer and information sciences,
		FOS: Electrical engineering, electronic engineering, information engineering,
		FOS: Electrical engineering, electronic engineering, information engineering
	}
}
@misc{Vaswani2017,
	title        = {Attention Is All You Need},
	author       = {
		Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and
		Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia
	},
	year         = 2017,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1706.03762},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {
		Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and
		information sciences, FOS: Computer and information sciences
	}
}
@misc{ViLBERT,
	title        = {
		ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for
		Vision-and-Language Tasks
	},
	author       = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
	year         = 2019,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1908.02265},
	url          = {https://arxiv.org/abs/1908.02265},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {
		Computer Vision and Pattern Recognition (cs.CV), Computation and Language
		(cs.CL), FOS: Computer and information sciences, FOS: Computer and
		information sciences
	}
}
